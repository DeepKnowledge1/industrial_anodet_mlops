
# ğŸš€ AnomaVision: State-of-the-Art Visual Anomaly Detection with AnomaVision

[![Version](https://img.shields.io/badge/version-0.1.0-blue.svg)](https://github.com/your-repo/AnomaVision)
[![Python](https://img.shields.io/badge/python-3.9+-green.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/pytorch-1.13.1-red.svg)](https://pytorch.org)
[![CUDA](https://img.shields.io/badge/CUDA-11.7-yellow.svg)](https://developer.nvidia.com/cuda-toolkit)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

> # **Notice:**  
> This project is a highly optimized and extended fork of [OpenAOI/anodet](https://github.com/OpenAOI/anodet).  
> All core algorithms and designs are adapted and enhanced from the original anodet repository.

---

![Example](notebooks/example_images/AnomaVision.png)

### ğŸ”¥ Production-Ready Deep Learning Library for Anomaly Detection

AnomaVision brings **cutting-edge AnomaVision-based anomaly detection** to your projects, optimized for both research and deployment. Whether you work in manufacturing, quality control, or research, AnomaVision offers blazing-fast inference, easy ONNX export, and a flexible, modern API.

---

### âœ¨ Why AnomaVision?

- **Lightning Fast & Memory Efficient**: Train and infer faster with up to 60% less memory usage.
- **ONNX Deployment Out-of-the-Box**: Go from training to production in minutesâ€”on the cloud or at the edge.
- **Mixed Precision Power**: Supports FP16/FP32 automatically for peak GPU/CPU performance.
- **Flexible & Modular**: Customize everythingâ€”backbone, feature layers, dimensionsâ€”no code rewrites needed.
- **Zero-Frustration Integration**: Train, export, and predict via Python or CLIâ€”one codebase, infinite workflows.

---

#### ğŸ“¸ Example: Detecting Anomalies on MVTec AD
![Example](notebooks/example_images/padim_example_image.png)

---

## ğŸš€ Get Started in Minutes

## ğŸ› ï¸ 1. Installation

```bash
git clone https://github.com/DeepKnowledge1/AnomaVision.git
cd AnomaVision

# Install with Poetry (recommended)
poetry shell
poetry install
````

---

## âš¡ 2. Quick Usage Examples

### Python API

```python
import anodet
import torch
from torch.utils.data import DataLoader

# Load dataset
dataset = anodet.AnodetDataset("path/to/train/good")
dataloader = DataLoader(dataset, batch_size=2)

# Select device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Build and train AnomaVision model
model = anodet.AnomaVision(
    backbone='resnet18',
    device=device,
    layer_indices=[0, 1],
    feat_dim=50
)
model.fit(dataloader)

# Export to ONNX for production deployment
from anodet.export import export_onnx
export_onnx(model, "AnomaVision_model.onnx", input_shape=(1, 3, 224, 224))

# Predict anomalies on new data
test_batch = next(iter(dataloader))[0]
image_scores, score_map = model.predict(test_batch)
```




#### Command-Line Power (CLI)

Train and export in a single command:

```bash
python main.py \
  --dataset_path "/path/to/dataset" \           # Path to the dataset folder (should contain 'train/good' subfolder)
  --model_data_path "./model_dir" \             # Directory to save trained model/distribution files and ONNX output
  --backbone resnet18 \                         # Backbone network to use ('resnet18' or 'wide_resnet50')
  --layer_indices 0 1 \                         # Indices of backbone layers to extract features from (space separated)
  --feat_dim 50 \                               # Number of random feature dimensions to select for training
  --batch_size 2 \                              # Batch size for training
  --output_model "AnomaVision_model.pt"               # Output filename for PT model
```

*Show all CLI options:*

```bash
python main.py --help
```

---

## ğŸ—‚ï¸ Project Structure

```
AnomaVision/
â”œâ”€â”€ anodet
â”‚   â”œâ”€â”€ datasets
â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚   â”‚   â”œâ”€â”€ mvtec_dataset.py
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”œâ”€â”€ mahalanobis.py
â”‚   â”œâ”€â”€ AnomaVision.py
â”‚   â”œâ”€â”€ patch_core.py
â”‚   â”œâ”€â”€ sampling_methods
â”‚   â”‚   â”œâ”€â”€ kcenter_greedy.py
â”‚   â”‚   â”œâ”€â”€ sampling_def.py
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ visualization
â”‚   â”‚   â”œâ”€â”€ boundary.py
â”‚   â”‚   â”œâ”€â”€ frame.py
â”‚   â”‚   â”œâ”€â”€ heatmap.py
â”‚   â”‚   â”œâ”€â”€ highlight.py
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __init__.py
â”œâ”€â”€ eval.py
â”œâ”€â”€ export.py
â”œâ”€â”€ main.py
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ AnomaVision_example.ipynb
â”‚   â”œâ”€â”€ patchcore_example.ipynb
â”‚   â”œâ”€â”€ tests_example.ipynb
â”œâ”€â”€ AnomaVision_example.ipynb
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
```

---

## ğŸ› ï¸ Powerful, Intuitive API

**Model Instantiation**

```python
AnomaVision(
    backbone='resnet18',         # 'resnet18' or 'wide_resnet50'
    device=torch.device('cuda'), # Target device
    layer_indices=[0, 1],        # List of ResNet layers (0: shallowest)
    feat_dim=50,                 # Number of random feature dims (see code)
    channel_indices=None         # Optional custom channel indices
)
```

**Training**

```python
model.fit(
    dataloader,      # torch DataLoader of "good" images
    extractions=1    # Optional: repeat count for augmentation
)
```

**Inference**

```python
image_scores, score_map = model.predict(
    batch,            # Input tensor (B, 3, H, W)
    gaussian_blur=True   # Apply Gaussian blur (default: True)
)
```

**ONNX Export**

```python
from anodet.export import export_onnx
export_onnx(
    model,
    "AnomaVision_model.onnx",
    input_shape=(1, 3, 224, 224) # (batch, channels, height, width)
)
```

---



### ğŸ§  Training
 


By default python *train.py*
```bash
python train.py    # Train AnomaVision on your selected dataset
```


additional to that, there are some of parameters you might need to change:
```bash
python train.py \
  --dataset_path "D:/01-DATA/bottle" \
  --model_data_path "./distributions/" \
  --backbone "resnet18" \
  --batch_size 2 \
  --output_model "padim_model.pt" \
  --layer_indices 0 \
  --feat_dim 50
```


### ğŸ¤– Inference



The following command can be used to run PyTorch inference from the command line:
```bash
python detect.py
```


### ğŸ“Š Evaluation
  Validate a trained model  model on a category of mvtech dataset or your custom dataset (has to have the same format).

```
    â”œâ”€â”€â”€ğŸ“‚ground_truth
    â”‚   â”œâ”€â”€â”€ğŸ“‚broken_large
    â”‚   â”œâ”€â”€â”€ğŸ“‚broken_small
    â”‚   â””â”€â”€â”€ğŸ“‚contamination
    â”œâ”€â”€â”€ğŸ“‚test
    â”‚   â”œâ”€â”€â”€ğŸ“‚broken_large
    â”‚   â”œâ”€â”€â”€ğŸ“‚broken_small
    â”‚   â”œâ”€â”€â”€ğŸ“‚contamination
    â”‚   â””â”€â”€â”€ğŸ“‚good
    â””â”€â”€â”€ğŸ“‚train
        â””â”€â”€â”€ğŸ“‚good
```

Command:

```
python eval.py
```




## ğŸ† Performance at a Glance

| Metric         | Original  | AnomaVision | Improvement   |
| -------------- | --------- | ----------- | ------------- |
| Memory Usage   | High      | Low         | 40-60% â†“      |
| Training Speed | Baseline  | Faster      | 15-25% â†‘      |
| Inference      | Baseline  | Faster      | 20-30% â†‘      |
| Precision      | FP32 only | Mixed       | 2x batch size |

* **ONNX Export**: Deploy anywhereâ€”cloud, edge, production.
* **Scalable**: Large batches on the same hardware.
* **Hybrid Precision**: FP16/FP32 auto on GPU, safe fallback on CPU.
* **Versatile**: Python & CLIâ€”your workflow, your way.

---

## ğŸ§© Architecture Highlights

* **`ResnetEmbeddingsExtractor`**: Feature extraction from any ResNet backbone, optimized for GPU/CPU.
* **`MahalanobisDistance`**: Fast, ONNX-exportable anomaly scoring module.
* **`AnomaVision`**: Fit, feature extraction, scoring, ONNX export, and inferenceâ€”all-in-one.
* **`export_onnx`**: Seamless export for fast, portable inference.

---

## ğŸ”— References & Acknowledgments

* **AnomaVision Paper**: [arxiv.org/abs/2011.08785](https://arxiv.org/abs/2011.08785)
* **TorchVision**: [pytorch.org/vision](https://pytorch.org/vision/)
* **Example Data**: [MVTec AD](https://www.mvtec.com/company/research/datasets/mvtec-ad)
* **Original Codebase**: [OpenAOI/anodet](https://github.com/OpenAOI/anodet)

*Special thanks to all original authors and contributors for their outstanding work.*

---

## ğŸ¤ Contributing

1. **Fork** this repo
2. **Create** a feature branch
3. **Commit & push** your changes
4. **Open a Pull Request**â€”collaboration welcome!

---

## ğŸ“¬ Contact

Questions? Feature requests?
**Deep Knowledge** â€“ [Deepp.Knowledge@gmail.com](mailto:Deepp.Knowledge@gmail.com)

---

â­ **If this project helps you, please star the repo and share it!** â­
